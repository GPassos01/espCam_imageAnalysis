#!/usr/bin/env python3
"""
Validador de Dados - Sistema de Monitoramento de Enchentes
Analisa dados MQTT em tempo real para verificar integridade
"""

import paho.mqtt.client as mqtt
import json
import time
from datetime import datetime
import threading

class DataValidator:
    def __init__(self):
        self.stats_history = []
        self.sensor_data = []
        self.alerts = []
        self.image_chunks = {}
        self.last_stats = None
        
        # Contadores de validaÃ§Ã£o
        self.total_messages = 0
        self.errors_found = 0
        self.warnings = 0
        
    def validate_network_stats(self, data):
        """Valida estatÃ­sticas de rede"""
        try:
            stats = json.loads(data)
            
            # VerificaÃ§Ãµes obrigatÃ³rias
            required_fields = ['timestamp', 'bytes_enviados', 'uptime', 'memoria_livre', 'taxa_compressao']
            missing_fields = [field for field in required_fields if field not in stats]
            
            if missing_fields:
                self.log_error(f"âŒ Campos ausentes: {missing_fields}")
                return False
                
            # ValidaÃ§Ã£o de valores crescentes
            if self.last_stats:
                if stats['bytes_enviados'] < self.last_stats['bytes_enviados']:
                    self.log_error(f"âŒ Bytes enviados DIMINUÃRAM: {stats['bytes_enviados']} < {self.last_stats['bytes_enviados']}")
                    return False
                    
                if stats['uptime'] < self.last_stats['uptime']:
                    self.log_error(f"âŒ Uptime DIMINUIU: {stats['uptime']} < {self.last_stats['uptime']}")
                    return False
                    
                # ValidaÃ§Ã£o de taxa de dados
                time_diff = stats['uptime'] - self.last_stats['uptime']
                bytes_diff = stats['bytes_enviados'] - self.last_stats['bytes_enviados']
                
                if time_diff > 0:
                    rate = bytes_diff / time_diff
                    if rate > 10000:  # Mais de 10KB/s Ã© suspeito
                        self.log_warning(f"âš ï¸ Taxa muito alta: {rate:.1f} bytes/s")
                    elif rate < 0:
                        self.log_error(f"âŒ Taxa negativa: {rate:.1f} bytes/s")
                        return False
            
            # Adicionar validaÃ§Ã£o da taxa de compressÃ£o aqui
            if not (0 <= stats.get('taxa_compressao', -1) <= 1):
                self.log_error(f"âŒ Taxa de compressÃ£o invÃ¡lida: {stats.get('taxa_compressao')} (deve ser 0-1)")
                return False
            elif stats.get('taxa_compressao', 0) > 0.8:
                 self.log_warning(f"âš ï¸ Taxa de compressÃ£o um pouco alta: {stats.get('taxa_compressao'):.2f}")

            self.last_stats = stats
            self.stats_history.append(stats)
            self.log_success(f"âœ… Stats vÃ¡lidos - {stats['bytes_enviados']} bytes, {stats['uptime']}s, CompressÃ£o: {stats.get('taxa_compressao', 0):.1%}")
            return True
            
        except json.JSONDecodeError as e:
            self.log_error(f"âŒ JSON invÃ¡lido: {e}")
            return False
    
    def validate_sensor_data(self, data):
        """Valida dados do sensor"""
        try:
            sensor = json.loads(data)
            
            required_fields = ['timestamp', 'current_size', 'difference', 'image_pair_id']
            missing_fields = [field for field in required_fields if field not in sensor]
            
            if missing_fields:
                self.log_error(f"âŒ Sensor - Campos ausentes: {missing_fields}")
                return False
            
            # ValidaÃ§Ã£o de diferenÃ§a
            if not 0 <= sensor['difference'] <= 1:
                self.log_error(f"âŒ DiferenÃ§a invÃ¡lida: {sensor['difference']} (deve ser 0-1)")
                return False
            
            self.sensor_data.append(sensor)
            self.log_success(f"âœ… Sensor vÃ¡lido - Pair ID: {sensor.get('image_pair_id')}, Tam. Atual: {sensor['current_size']} bytes, Diff: {sensor['difference']:.1%}")
            return True
            
        except Exception as e:
            self.log_error(f"âŒ Erro sensor: {e}")
            return False
    
    def validate_alert(self, data):
        """Valida alertas"""
        try:
            alert = json.loads(data)
            
            if 'alert' not in alert or 'timestamp' not in alert:
                self.log_error("âŒ Alerta sem campos obrigatÃ³rios")
                return False
            
            self.alerts.append(alert)
            self.log_success(f"âœ… Alerta vÃ¡lido: {alert['alert']}")
            return True
            
        except Exception as e:
            self.log_error(f"âŒ Erro alerta: {e}")
            return False
    
    def on_message(self, client, userdata, msg):
        """Callback para mensagens MQTT"""
        self.total_messages += 1
        topic = msg.topic
        
        # Verificar se Ã© um chunk de imagem (dados binÃ¡rios)
        if topic.startswith("enchentes/imagem/dados"):
            # Para chunks de imagem, trabalhar com dados binÃ¡rios
            payload_size = len(msg.payload)
            print(f"\nğŸ“¨ [{datetime.now().strftime('%H:%M:%S')}] {topic} ({payload_size} bytes - binÃ¡rio)")
            self.validate_image_chunk(topic, msg.payload)
            return
        
        # Para outros tÃ³picos, decodificar como texto
        try:
            payload = msg.payload.decode('utf-8')
            print(f"\nğŸ“¨ [{datetime.now().strftime('%H:%M:%S')}] {topic} ({len(payload)} bytes)")
            
            # Roteamento por tÃ³pico
            if topic == "enchentes/rede/estatisticas":
                self.validate_network_stats(payload)
            elif topic == "enchentes/sensores":
                self.validate_sensor_data(payload)
            elif topic == "enchentes/alertas":
                self.validate_alert(payload)
                
        except UnicodeDecodeError as e:
            self.log_error(f"âŒ Erro de decodificaÃ§Ã£o UTF-8: {e}")
            # Tentar com outros encodings
            try:
                payload = msg.payload.decode('latin-1')
                print(f"âš ï¸ Decodificado com latin-1: {len(payload)} chars")
            except Exception as e2:
                self.log_error(f"âŒ Falha em todos os encodings: {e2}")
        except Exception as e:
            self.log_error(f"âŒ Erro geral no processamento: {e}")
    
    def validate_image_chunk(self, topic, data):
        """Valida chunks de imagem - dados binÃ¡rios"""
        try:
            # Extrair offset e tamanho total do tÃ³pico
            # Formato esperado: enchentes/imagem/dados/{tipo}/{pair_id}/{offset}/{total_size}
            parts = topic.split('/')
            if len(parts) == 7: # Espera 7 partes: enchentes, imagem, dados, tipo, pair_id, offset, total_size
                image_type = parts[3]
                pair_id = parts[4]
                offset = int(parts[5]) # Corrigido de parts[3]
                total_size = int(parts[6]) # Corrigido de parts[4]
                
                # Usar uma combinaÃ§Ã£o mais robusta para chunk_id que inclua pair_id e tipo
                chunk_id = f"{pair_id}_{image_type}_{total_size}"
                    
                if chunk_id not in self.image_chunks:
                    self.image_chunks[chunk_id] = {
                        'chunks': {}, # Armazenar chunks por offset para facilitar a verificaÃ§Ã£o de lacunas
                        'total_size': total_size,
                        'received_bytes': 0,
                        'pair_id': pair_id,
                        'image_type': image_type
                    }
                
                # Para dados binÃ¡rios, usar len(data) diretamente
                chunk_size = len(data)
                self.image_chunks[chunk_id]['chunks'][offset] = chunk_size # Armazena o tamanho do chunk no offset
                self.image_chunks[chunk_id]['received_bytes'] += chunk_size
                
                self.log_success(f"âœ… Chunk {image_type} (Pair: {pair_id}) {offset}/{total_size} - {chunk_size} bytes")
                
                # Verificar se recebemos todos os chunks
                if self.image_chunks[chunk_id]['received_bytes'] >= total_size:
                    # Adicionalmente, verificar se todos os offsets esperados foram recebidos (opcional, mais complexo)
                    self.log_success(f"ğŸ–¼ï¸ Imagem {image_type} (Pair: {pair_id}) completa! Total: {self.image_chunks[chunk_id]['received_bytes']}/{total_size} bytes")
            else:
                self.log_error(f"âŒ Formato de tÃ³pico de chunk invÃ¡lido: {topic} (Esperado 7 partes, obteve {len(parts)})")
                        
        except Exception as e:
            self.log_error(f"âŒ Erro chunk: {e} (TÃ³pico: {topic})")
    
    def log_success(self, msg):
        print(f"  {msg}")
    
    def log_warning(self, msg):
        self.warnings += 1
        print(f"  ğŸŸ¡ {msg}")
    
    def log_error(self, msg):
        self.errors_found += 1
        print(f"  ğŸ”´ {msg}")
    
    def print_summary(self):
        """Imprime resumo da validaÃ§Ã£o"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š RESUMO DA VALIDAÃ‡ÃƒO")
        print(f"{'='*60}")
        print(f"ğŸ“¬ Total de mensagens: {self.total_messages}")
        print(f"ğŸ“ˆ Stats processados: {len(self.stats_history)}")
        print(f"ğŸ”¬ Dados de sensores: {len(self.sensor_data)}")
        print(f"ğŸš¨ Alertas recebidos: {len(self.alerts)}")
        print(f"ğŸ–¼ï¸ Chunks de imagem: {len(self.image_chunks)}")
        print(f"âœ… Status: {self.total_messages - self.errors_found} OK")
        print(f"ğŸŸ¡ Avisos: {self.warnings}")
        print(f"ğŸ”´ Erros: {self.errors_found}")
        
        if self.last_stats:
            efficiency = self.calculate_efficiency()
            print(f"\nğŸ“Š ESTATÃSTICAS FINAIS:")
            print(f"ğŸ“¤ Bytes enviados: {self.last_stats['bytes_enviados']:,}")
            print(f"â±ï¸ Uptime: {self.last_stats['uptime']}s")
            print(f"ğŸ§  MemÃ³ria livre: {self.last_stats['memoria_livre']:,} bytes")
            print(f"ğŸ“Š EficiÃªncia: {efficiency:.1f}%")
    
    def calculate_efficiency(self):
        """Calcula eficiÃªncia do sistema"""
        if len(self.stats_history) < 2:
            return 0
        
        # Estimar quantas imagens poderiam ter sido enviadas
        uptime = self.last_stats['uptime']
        expected_images = uptime // 30  # A cada 30 segundos
        actual_images = len(self.sensor_data)
        
        if expected_images > 0:
            return (actual_images / expected_images) * 100
        return 0

    def analyze_trends(self):
        """Analisa tendÃªncias nos dados"""
        if len(self.stats_history) < 5:
            return
            
        print(f"\nğŸ“ˆ ANÃLISE DE TENDÃŠNCIAS:")
        
        # Analisar crescimento de bytes
        recent_stats = self.stats_history[-5:]
        byte_growth = []
        for i in range(1, len(recent_stats)):
            growth = recent_stats[i]['bytes_enviados'] - recent_stats[i-1]['bytes_enviados']
            byte_growth.append(growth)
        
        avg_growth = sum(byte_growth) / len(byte_growth)
        print(f"ğŸ“Š Crescimento mÃ©dio: {avg_growth:.1f} bytes/perÃ­odo")
        
        # Projetar prÃ³ximos 5 minutos
        current_bytes = recent_stats[-1]['bytes_enviados']
        projection = current_bytes + (avg_growth * 20)  # 20 perÃ­odos â‰ˆ 5 min
        print(f"ğŸ”® ProjeÃ§Ã£o 5min: {projection:,.0f} bytes")
        
        # Analisar eficiÃªncia de compressÃ£o
        compressions = []
        for stat_item in self.stats_history[-10:]: # Usar stats_history
            if 'taxa_compressao' in stat_item:
                compressions.append(stat_item['taxa_compressao'])
        
        if compressions:
            avg_compression = sum(compressions) / len(compressions)
            print(f"ğŸ“¦ CompressÃ£o mÃ©dia (de stats): {avg_compression:.1%}")
            
            if avg_compression > 0.8:
                print(f"âš ï¸ CompressÃ£o mÃ©dia baixa (de stats) detectada!")
            elif avg_compression < 0.1 and avg_compression > 0: # Evitar 0 se nÃ£o houver compressÃ£o
                print(f"âœ… Ã“tima eficiÃªncia de compressÃ£o mÃ©dia (de stats)!")
            elif avg_compression == 0:
                print(f"â„¹ï¸ CompressÃ£o mÃ©dia (de stats) Ã© zero. Isso pode ser normal se apenas a primeira imagem foi enviada ou se nÃ£o houve mudanÃ§as.")
    
    def check_data_quality(self):
        """Verifica qualidade dos dados"""
        print(f"\nğŸ” VERIFICAÃ‡ÃƒO DE QUALIDADE:")
        
        # Verificar consistÃªncia temporal
        timestamps = [stat['timestamp'] for stat in self.stats_history[-10:]]
        if len(timestamps) > 1:
            intervals = []
            for i in range(1, len(timestamps)):
                interval = timestamps[i] - timestamps[i-1]
                intervals.append(interval)
            
            avg_interval = sum(intervals) / len(intervals)
            max_gap = max(intervals)
            
            print(f"â±ï¸ Intervalo mÃ©dio: {avg_interval:.1f}s")
            if max_gap > avg_interval * 2:
                print(f"âš ï¸ Gap detectado: {max_gap:.1f}s")
            else:
                print(f"âœ… TemporizaÃ§Ã£o consistente")
        
        # Verificar variabilidade dos dados
        if len(self.sensor_data) > 5:
            sizes = [s['current_size'] for s in self.sensor_data[-10:]]
            avg_size = sum(sizes) / len(sizes)
            variance = sum([(s - avg_size)**2 for s in sizes]) / len(sizes)
            std_dev = variance**0.5
            
            print(f"ğŸ“ Tamanho mÃ©dio: {avg_size:.0f} bytes")
            print(f"ğŸ“Š Desvio padrÃ£o: {std_dev:.0f} bytes")
            
            if std_dev > avg_size * 0.5:
                print(f"ğŸ“ˆ Alta variabilidade detectada")
            else:
                print(f"ğŸ“Š Variabilidade normal")

def main():
    print("ğŸ” VALIDADOR DE DADOS - Sistema de Monitoramento de Enchentes")
    print("ğŸ¯ Conectando ao broker MQTT...")
    
    validator = DataValidator()
    
    client = mqtt.Client()
    client.on_message = validator.on_message
    
    try:
        client.connect("192.168.1.2", 1883, 60)
        
        # Subscrever a todos os tÃ³picos
        topics = [
            "enchentes/rede/estatisticas",
            "enchentes/sensores", 
            "enchentes/alertas",
            "enchentes/imagem/dados/+/+/+/+" # Corrigido de +/+
        ]
        
        for topic in topics:
            client.subscribe(topic)
            print(f"ğŸ“¡ Subscrito: {topic}")
        
        print(f"\nğŸš€ Iniciando validaÃ§Ã£o... (Ctrl+C para parar)")
        
        # Timer para relatÃ³rios periÃ³dicos
        def periodic_report():
            while True:
                time.sleep(30)  # RelatÃ³rio a cada 30 segundos
                if validator.total_messages > 0:
                    print(f"\n{'='*50}")
                    print(f"ğŸ“Š RELATÃ“RIO PERIÃ“DICO - {datetime.now().strftime('%H:%M:%S')}")
                    print(f"{'='*50}")
                    validator.print_summary()
                    validator.analyze_trends()  # Nova anÃ¡lise
                    validator.check_data_quality()  # Nova verificaÃ§Ã£o
        
        report_thread = threading.Thread(target=periodic_report, daemon=True)
        report_thread.start()
        
        client.loop_forever()
        
    except KeyboardInterrupt:
        print(f"\n\nğŸ›‘ Parando validaÃ§Ã£o...")
        validator.print_summary()
    except Exception as e:
        print(f"âŒ Erro: {e}")
    finally:
        client.disconnect()

if __name__ == "__main__":
    main() 